{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ham_params:  t=1, alpha=1.25, mu=0, beta=varying, J=5, U=varying, normalise=True,\n",
      "\n",
      "Tasks per chain: 5,\n",
      "Each doing 1000 steps,\n",
      "5000 total chain length,\n",
      "500 samples,\n",
      "\n",
      "MCMC_params:  N_steps=1000, N_burn_in=1000, thin=10, proposal=<function p_multi_site_uniform_reflect at 0x2b7fe796cf80>, accept_function=<function perturbation_accept at 0x2b7fe796e320>, warnings=False,\n",
      "Getting environment variables\n",
      "job_id = -1, chain_id = -1, task_id = 50, submit_dir = /rds/general/user/tch14/home/HPC_data/test\n",
      "Generating initial state as this is the first run with these params\n",
      "Diagonalisation benchmark: 2.07 seconds\n",
      "N = 250: 0% through after 0.00m             rejects: classical = 100% quantum = 100% overall = 100%\n",
      "N = 250: 10% through after 0.04m             rejects: classical = 100% quantum = 9% overall = 100%\n",
      "N = 250: 20% through after 0.07m             rejects: classical = 100% quantum = 14% overall = 100%\n",
      "N = 250: 30% through after 0.11m             rejects: classical = 100% quantum = 32% overall = 100%\n",
      "N = 250: 40% through after 0.15m             rejects: classical = 100% quantum = 31% overall = 100%\n",
      "N = 250: 50% through after 0.18m             rejects: classical = 100% quantum = 35% overall = 100%\n",
      "N = 250: 60% through after 0.22m             rejects: classical = 100% quantum = 41% overall = 100%\n",
      "N = 250: 70% through after 0.26m             rejects: classical = 100% quantum = 44% overall = 100%\n",
      "N = 250: 80% through after 0.30m             rejects: classical = 100% quantum = 46% overall = 100%\n",
      "N = 250: 90% through after 0.33m             rejects: classical = 100% quantum = 51% overall = 100%\n",
      "N = 160: 0% through after 0.00m             rejects: classical = 100% quantum = 100% overall = 100%\n",
      "N = 160: 10% through after 0.12m             rejects: classical = 100% quantum = 46% overall = 100%\n",
      "N = 160: 20% through after 0.24m             rejects: classical = 100% quantum = 64% overall = 100%\n",
      "N = 160: 30% through after 0.37m             rejects: classical = 99% quantum = 59% overall = 100%\n",
      "N = 160: 40% through after 0.52m             rejects: classical = 99% quantum = 59% overall = 100%\n",
      "N = 160: 50% through after 0.68m             rejects: classical = 99% quantum = 60% overall = 100%\n",
      "N = 160: 60% through after 0.85m             rejects: classical = 99% quantum = 62% overall = 100%\n",
      "N = 160: 70% through after 0.99m             rejects: classical = 99% quantum = 60% overall = 100%\n",
      "N = 160: 80% through after 1.14m             rejects: classical = 99% quantum = 59% overall = 100%\n",
      "N = 160: 90% through after 1.29m             rejects: classical = 99% quantum = 59% overall = 100%\n",
      "N = 110: 0% through after 0.00m             rejects: classical = 100% quantum = 100% overall = 100%\n",
      "N = 110: 10% through after 0.06m             rejects: classical = 99% quantum = 37% overall = 100%\n",
      "N = 110: 20% through after 0.12m             rejects: classical = 99% quantum = 65% overall = 100%\n",
      "N = 110: 30% through after 0.18m             rejects: classical = 99% quantum = 62% overall = 100%\n",
      "N = 110: 40% through after 0.24m             rejects: classical = 99% quantum = 65% overall = 100%\n",
      "N = 110: 50% through after 0.36m             rejects: classical = 97% quantum = 75% overall = 99%\n",
      "N = 110: 60% through after 0.45m             rejects: classical = 96% quantum = 77% overall = 99%\n",
      "N = 110: 70% through after 0.52m             rejects: classical = 96% quantum = 76% overall = 99%\n",
      "N = 110: 80% through after 0.63m             rejects: classical = 96% quantum = 75% overall = 99%\n",
      "N = 110: 90% through after 0.76m             rejects: classical = 95% quantum = 79% overall = 99%\n",
      "50 seconds, final saving in /rds/general/user/tch14/home/FKMC/batchscripts / 50_-1.npz\n",
      "Copying to /rds/general/user/tch14/home/HPC_data/test/data)\n",
      "\n",
      "Requested MCMC steps: 100\n",
      "Time: 49 seconds \n",
      "Estimated task runtime for 1000 steps: 8.0 minutes \n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "A TU plot recording magnetisation, IPR and DOS\n",
    "    \n",
    "Hamiltonian:J = 5\n",
    "\n",
    "MCMC:\n",
    "Overall target steps: 1e5 or 1e6\n",
    "Thinning: 10\n",
    "\n",
    "'''\n",
    "from munch import Munch\n",
    "import numpy as np\n",
    "\n",
    "########## Hamiltonian parameters ###########################################################################\n",
    "Ham_params = Munch(\n",
    "    t = 1,\n",
    "    alpha = 1.25,\n",
    "    mu = 0,\n",
    "    beta = 'varying',\n",
    "    J = 5,\n",
    "    U = 'varying',\n",
    "    normalise = True #Whether the long range interaction should be normalised against the CDW or not.\n",
    ")\n",
    "print('Ham_params: ', ' '.join(f'{k}={v},' for k,v in Ham_params.items()))\n",
    "\n",
    "########## Variable Hamiltonian parameters ###########################################################################\n",
    "chain_exts = np.arange(0,10) #the number of times to extend the chain maximum is about 50 on CX1\n",
    "N_steps = int(1e3) #the number of MCMC steps in each individual task\n",
    "thin = 10\n",
    "print(f'''\n",
    "Tasks per chain: {chain_exts.size},\n",
    "Each doing {N_steps} steps,\n",
    "{chain_exts.size*N_steps} total chain length,\n",
    "{chain_exts.size*N_steps // thin} samples,\n",
    "''')\n",
    "\n",
    "Rs = np.arange(10)\n",
    "Us = np.linspace(0, 8, 9) \n",
    "Ts = np.linspace(2, 2.5, 10)\n",
    "\n",
    "Ns = np.array([250,160,110])\n",
    "\n",
    "from FKMC.montecarlo import Eigenspectrum_IPR_all\n",
    "def loggerfactory(): return Eigenspectrum_IPR_all(bins = 2000, limit = 5)\n",
    "\n",
    "structure_names = ['Rs','Us','Ts',] #Ns and chain_exts is dealt with separately\n",
    "structure_dimensions = [Rs,Us,Ts,]\n",
    "\n",
    "########## Monte Carlo parameters ###########################################################################\n",
    "from FKMC.montecarlo import p_multi_site_uniform_reflect, perturbation_accept\n",
    "\n",
    "initial_states = Munch(\n",
    "    CDW1 = lambda N: np.arange(N, dtype = np.float64) % 2,\n",
    "    CDW2 = lambda N: (np.arange(N, dtype = np.float64)+1) % 2,\n",
    "    zeros = lambda N: np.zeros(N, dtype = np.float64),\n",
    "    ones = lambda N: np.ones(N, dtype = np.float64),\n",
    ")\n",
    "\n",
    "state_factory = initial_states.CDW1\n",
    "\n",
    "MCMC_params = Munch(\n",
    "        N_steps = N_steps,\n",
    "        N_burn_in = N_steps,\n",
    "        thin = thin,\n",
    "        proposal = p_multi_site_uniform_reflect,\n",
    "        accept_function = perturbation_accept,\n",
    "        warnings = False,\n",
    "    )\n",
    "print('MCMC_params: ', ' '.join(f'{k}={v},' for k,v in MCMC_params.items()))\n",
    "\n",
    "########## Batch Job Structure ###########################################################################\n",
    "from itertools import product as cartesian_product\n",
    "\n",
    "config_product = cartesian_product(*structure_dimensions)\n",
    "\n",
    "#give information to the dispatch script\n",
    "batch_params = Munch(\n",
    "    total_jobs = np.prod([len(dim) for dim in structure_dimensions]),\n",
    "    chain_exts = chain_exts,\n",
    "    structure_names = structure_names, #names of each of the dimensions like ['Ts', 'Alphas']\n",
    "    structure_dimensions = structure_dimensions, #the dimensions themselves like [np.linspace(0.1,5,100), np.linspace(0.1,2,100)]\n",
    "    indices = (0, np.prod([len(dim) for dim in structure_dimensions])),\n",
    ")\n",
    "#bath_params_end_flag this is here to signal the end of the batch_params variable\n",
    "\n",
    "########## Parameters particular to this job ################################################################\n",
    "\n",
    "from itertools import product, islice\n",
    "from pathlib import Path\n",
    "import os\n",
    "from time import time, sleep\n",
    "import sys\n",
    "import shutil\n",
    "from FKMC.import_funcs import timefmt\n",
    "\n",
    "print('Getting environment variables')\n",
    "debug = (os.getenv('DEBUG', 'True') == 'True')\n",
    "submit_dir = Path(os.getenv('SUBMIT_DIR', Path('~/HPC_data/test/').expanduser()))\n",
    "\n",
    "job_id = int(os.getenv('JOB_ID', -1))\n",
    "chain_id = int(os.getenv('CHAIN_ID', -1))\n",
    "task_id = int(os.getenv('TASK_ID', 50))\n",
    "\n",
    "print(f'job_id = {job_id}, chain_id = {chain_id}, task_id = {task_id}, submit_dir = {submit_dir}')\n",
    "\n",
    "Is_todo = np.arange(len(Ns))\n",
    "Ns_todo = Ns.copy()\n",
    "logs = [None for _ in Ns]\n",
    "\n",
    "filename = f'{task_id}_{chain_id}.npz'\n",
    "\n",
    "if not debug and (submit_dir / 'data' / filename).exists():\n",
    "    print(f'Job file {filename} already exists')\n",
    "    print(f'Loading {filename} to retrieve the work')\n",
    "    d = Munch(np.load(submit_dir / 'data' / filename, allow_pickle = True))\n",
    "    logs = d['logs'][()]\n",
    "    todo = (logs == None)\n",
    "    Is_todo = Is_todo[todo]\n",
    "    Ns_todo = Ns_todo[todo]\n",
    "    print(f'Ns_todo = {Ns_todo}')\n",
    "    \n",
    "\n",
    "\n",
    "(R,U,T,), = list(islice(config_product, task_id, task_id + 1))\n",
    "  \n",
    "Ham_params.U = U\n",
    "Ham_params.beta = 1 / T\n",
    "\n",
    "########## Set up debugging and sleep ################################################################\n",
    "original_MCMC_params = MCMC_params.copy()\n",
    "\n",
    "if debug:\n",
    "    MCMC_params.N_burn_in = 0\n",
    "    MCMC_params.N_steps = 100\n",
    "    MCMC_params.thin = 1\n",
    "    Ham_params.beta = 1 / 2.0 #choose the critical temp where the calculations take longest\n",
    "    \n",
    "    \n",
    "\n",
    "##sleep if necessary\n",
    "if not debug: \n",
    "    sleeptime = np.random.random() * (10)\n",
    "    print(f'Waiting for {sleeptime:.0f} seconds to randomise the finish time')\n",
    "    sleep(sleeptime)\n",
    "\n",
    "\n",
    "########## Load the previous states ################################################################\n",
    "\n",
    "#load in the last state from the previous run or use initial_states\n",
    "if not debug and chain_id > 0:\n",
    "    MCMC_params.N_burn_in = 0\n",
    "    \n",
    "    previous_filename = f'{task_id}_{chain_id-1}.npz'\n",
    "    \n",
    "    print(f'Loading {previous_filename} to retrieve the last state')\n",
    "    d = Munch(np.load(submit_dir / 'data' / previous_filename, allow_pickle = True))\n",
    "    previous_logs = d['logs'][()]\n",
    "    if any(log == None for log in previous_logs):\n",
    "        print(\"Previous job didn't finish, exiting\")\n",
    "        raise ValueError\n",
    "        \n",
    "    previous_states = {log.N_sites : log.last_state for log in previous_logs}\n",
    "else:\n",
    "    print('Generating initial state as this is the first run with these params')\n",
    "    previous_states = {N : state_factory(N) for N in Ns_todo}\n",
    "\n",
    "from FKMC.general import tridiagonal_diagonalisation_benchmark\n",
    "benchmark_time = tridiagonal_diagonalisation_benchmark()\n",
    "print(f\"Diagonalisation benchmark: {benchmark_time:.2f} seconds\")\n",
    "\n",
    "########## The actual simulation code ################################################################\n",
    "from FKMC.montecarlo import FK_mcmc\n",
    "\n",
    "Ham_params.J_matrix = '...'\n",
    "MCMC_params.state = '...'\n",
    "t0 = time()\n",
    "\n",
    "for i, N in zip(Is_todo, Ns_todo):\n",
    "    MCMC_params.state = previous_states[N]\n",
    "    MCMC_params.logger = loggerfactory()\n",
    "    \n",
    "    t0 = time()\n",
    "    logs[i] = FK_mcmc(**MCMC_params, parameters = Ham_params)\n",
    "    logs[i].time = time() - t0\n",
    "    \n",
    "    #restore these parameters for saving\n",
    "    MCMC_params.N_burn_in = original_MCMC_params.N_burn_in\n",
    "    \n",
    "    np.savez_compressed(filename, \n",
    "        Ns = Ns, parameters = Ham_params, MCMC_params = MCMC_params, \n",
    "        structure_names = structure_names,\n",
    "        structure_dimensions = structure_dimensions,        \n",
    "        chain_id = chain_id,\n",
    "        task_id = task_id,\n",
    "        logs = logs, allow_pickle = True,\n",
    "        desc = ''\n",
    "        )\n",
    "    \n",
    "    shutil.copy(filename, submit_dir / 'data')\n",
    "\n",
    "t = time() - t0\n",
    "print(f'{t:.0f} seconds, final saving in {Path.cwd()} / {filename}')\n",
    "print(f'Copying to {submit_dir}/data)')\n",
    "\n",
    "print(f'''\n",
    "Requested MCMC steps: {MCMC_params.N_steps}\n",
    "Time: {timefmt(t)} \n",
    "Estimated task runtime for 1000 steps: {timefmt(t * 1000 / MCMC_params.N_steps)} \n",
    "''')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda3/base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
