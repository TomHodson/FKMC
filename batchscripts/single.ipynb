{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ham_params:  t=1, alpha=1.25, mu=0, beta=varying, J=5, U=5, normalise=True,\n",
      "\n",
      "Tasks per chain: 10,\n",
      "Each doing 10000 steps,\n",
      "100000 total chain length,\n",
      "1000 samples,\n",
      "\n",
      "MCMC_params:  N_steps=10000, N_burn_in=10000, thin=100, proposal=<function p_multi_site_uniform_reflect at 0x2b7bf88d3320>, accept_function=<function perturbation_accept at 0x2b7bf88d3680>, warnings=False,\n",
      "Getting environment variables\n",
      "job_id = -1, chain_id = -1, task_id = 0, submit_dir = /rds/general/user/tch14/home/HPC_data/test\n",
      "Job file 0_-1.npz already exists\n",
      "Loading 0_-1.npz to retrieve the work\n",
      "Ns_todo = []\n",
      "T = 1.0\n",
      "Generating initial state as this is the first run with these params\n",
      "Diagonalisation benchmark: 1.75 seconds\n",
      "0 seconds, final saving in /rdsgpfs/general/user/tch14/home/FKMC/batchscripts / 0_-1.npz\n",
      "Copying to /rds/general/user/tch14/home/HPC_data/test/data)\n",
      "\n",
      "Requested MCMC steps: 10\n",
      "Time: 0 seconds \n",
      "Estimated task runtime for 1000 steps: 0 seconds \n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "A script to do just a few points in parameter space:\n",
    "U = 5\n",
    "J = 5\n",
    "\n",
    "T = 1.5 below Tc\n",
    "T = 2.5 above Tc\n",
    "\n",
    "\n",
    "'''\n",
    "from munch import Munch\n",
    "import numpy as np\n",
    "\n",
    "########## Hamiltonian parameters ###########################################################################\n",
    "Ham_params = Munch(\n",
    "    t = 1,\n",
    "    alpha = 1.25,\n",
    "    mu = 0,\n",
    "    beta = 'varying',\n",
    "    J = 5,\n",
    "    U = 5,\n",
    "    normalise = True #Whether the long range interaction should be normalised against the CDW or not.\n",
    ")\n",
    "print('Ham_params: ', ' '.join(f'{k}={v},' for k,v in Ham_params.items()))\n",
    "\n",
    "########## Variable Hamiltonian parameters ###########################################################################\n",
    "chain_exts = np.arange(0,10) #the number of times to extend the chain maximum is about 50 on CX1\n",
    "N_steps = int(1e4) #the number of MCMC steps in each individual task\n",
    "thin = 100\n",
    "print(f'''\n",
    "Tasks per chain: {chain_exts.size},\n",
    "Each doing {N_steps} steps,\n",
    "{chain_exts.size*N_steps} total chain length,\n",
    "{chain_exts.size*N_steps // thin} samples,\n",
    "''')\n",
    "\n",
    "Ts = np.array([1,1.5,2,2.5])\n",
    "Ns = np.logspace(np.log10(70), np.log10(300), 10, dtype = np.int) // 10 * 10\n",
    "\n",
    "structure_names = ['Ts',] #Ns and chain_exts is dealt with separately\n",
    "structure_dimensions = [Ts,]\n",
    "\n",
    "########## Monte Carlo parameters ###########################################################################\n",
    "from FKMC.montecarlo import Eigenspectrum_IPR_all, p_multi_site_uniform_reflect, perturbation_accept\n",
    "\n",
    "initial_states = Munch(\n",
    "    CDW1 = lambda N: np.arange(N, dtype = np.float64) % 2,\n",
    "    CDW2 = lambda N: (np.arange(N, dtype = np.float64)+1) % 2,\n",
    "    zeros = lambda N: np.zeros(N, dtype = np.float64),\n",
    "    ones = lambda N: np.ones(N, dtype = np.float64),\n",
    ")\n",
    "\n",
    "state_factory = initial_states.CDW1\n",
    "def loggerfactory(): return Eigenspectrum_IPR_all(bins = 2000, limit = 5)\n",
    "\n",
    "MCMC_params = Munch(\n",
    "        N_steps = N_steps,\n",
    "        N_burn_in = N_steps,\n",
    "        thin = thin,\n",
    "        proposal = p_multi_site_uniform_reflect,\n",
    "        accept_function = perturbation_accept,\n",
    "        warnings = False,\n",
    "    )\n",
    "print('MCMC_params: ', ' '.join(f'{k}={v},' for k,v in MCMC_params.items()))\n",
    "\n",
    "########## Batch Job Structure ###########################################################################\n",
    "from itertools import product as cartesian_product\n",
    "\n",
    "config_product = cartesian_product(*structure_dimensions)\n",
    "\n",
    "#give information to the dispatch script\n",
    "batch_params = Munch(\n",
    "    total_jobs = len(Ts),\n",
    "    chain_exts = chain_exts,\n",
    "    structure_names = structure_names, #names of each of the dimensions like ['Ts', 'Alphas']\n",
    "    structure_dimensions = structure_dimensions, #the dimensions themselves like [np.linspace(0.1,5,100), np.linspace(0.1,2,100)]\n",
    "    indices = (0, len(Ts)),\n",
    ")\n",
    "#bath_params_end_flag this is here to signal the end of the batch_params variable\n",
    "\n",
    "########## Parameters particular to this job ################################################################\n",
    "\n",
    "from itertools import product, islice\n",
    "from pathlib import Path\n",
    "import os\n",
    "from time import time, sleep\n",
    "import sys\n",
    "import shutil\n",
    "from FKMC.import_funcs import timefmt\n",
    "\n",
    "print('Getting environment variables')\n",
    "debug = (os.getenv('DEBUG', 'True') == 'True')\n",
    "submit_dir = Path(os.getenv('SUBMIT_DIR', Path('~/HPC_data/test/').expanduser()))\n",
    "\n",
    "job_id = int(os.getenv('JOB_ID', -1))\n",
    "chain_id = int(os.getenv('CHAIN_ID', -1))\n",
    "task_id = int(os.getenv('TASK_ID', 0))\n",
    "\n",
    "print(f'job_id = {job_id}, chain_id = {chain_id}, task_id = {task_id}, submit_dir = {submit_dir}')\n",
    "\n",
    "Is_todo = np.arange(len(Ns))\n",
    "Ns_todo = Ns.copy()\n",
    "logs = [None for _ in Ns]\n",
    "\n",
    "filename = f'{task_id}_{chain_id}.npz'\n",
    "\n",
    "if (submit_dir / 'data' / filename).exists():\n",
    "    print(f'Job file {filename} already exists')\n",
    "    print(f'Loading {filename} to retrieve the work')\n",
    "    d = Munch(np.load(submit_dir / 'data' / filename, allow_pickle = True))\n",
    "    logs = d['logs'][()]\n",
    "    todo = (logs == None)\n",
    "    Is_todo = Is_todo[todo]\n",
    "    Ns_todo = Ns_todo[todo]\n",
    "    print(f'Ns_todo = {Ns_todo}')\n",
    "    \n",
    "\n",
    "\n",
    "(T,), = list(islice(config_product, task_id, task_id + 1))\n",
    "print(f'T = {T}')\n",
    "    \n",
    "\n",
    "Ham_params.beta = 1 / T\n",
    "\n",
    "########## Set up debugging and sleep ################################################################\n",
    "\n",
    "if debug:\n",
    "    MCMC_params.N_burn_in = 0\n",
    "    MCMC_params.N_steps = 10\n",
    "    MCMC_params.thin = 1\n",
    "    Ham_params.beta = 1 / 2.0 #choose the critical temp where the calculations take longest\n",
    "    \n",
    "    \n",
    "\n",
    "##sleep if necessary\n",
    "if not debug: \n",
    "    sleeptime = np.random.random() * (10)\n",
    "    print(f'Waiting for {sleeptime:.0f} seconds to randomise the finish time')\n",
    "    sleep(sleeptime)\n",
    "\n",
    "\n",
    "########## Load the previous states ################################################################\n",
    "\n",
    "#load in the last state from the previous run or use initial_states\n",
    "if chain_id > 0:\n",
    "    MCMC_params.N_burn_in = 0\n",
    "    \n",
    "    previous_filename = f'{task_id}_{chain_id-1}.npz'\n",
    "    \n",
    "    print(f'Loading {previous_filename} to retrieve the last state')\n",
    "    d = Munch(np.load(submit_dir / 'data' / previous_filename, allow_pickle = True))\n",
    "    previous_logs = d['logs'][()]\n",
    "    if any(log == None for log in previous_logs):\n",
    "        print(\"Previous job didn't finish, exiting\")\n",
    "        raise ValueError\n",
    "        \n",
    "    previous_states = {log.N_sites : log.last_state for log in previous_logs}\n",
    "else:\n",
    "    print('Generating initial state as this is the first run with these params')\n",
    "    previous_states = {N : state_factory(N) for N in Ns_todo}\n",
    "\n",
    "from FKMC.general import tridiagonal_diagonalisation_benchmark\n",
    "benchmark_time = tridiagonal_diagonalisation_benchmark()\n",
    "print(f\"Diagonalisation benchmark: {benchmark_time:.2f} seconds\")\n",
    "\n",
    "########## The actual simulation code ################################################################\n",
    "from FKMC.montecarlo import FK_mcmc\n",
    "\n",
    "Ham_params['J_matrix'] = '...'\n",
    "MCMC_params['state'] = '...'\n",
    "t0 = time()\n",
    "\n",
    "for i, N in zip(Is_todo, Ns_todo):\n",
    "    MCMC_params.state = previous_states[N]\n",
    "    MCMC_params.logger = loggerfactory()\n",
    "    \n",
    "    t0 = time()\n",
    "    logs[i] = FK_mcmc(**MCMC_params, parameters = Ham_params)\n",
    "    logs[i].time = time() - t0\n",
    "    \n",
    "    np.savez_compressed(filename, \n",
    "        Ns = Ns, parameters = Ham_params, MCMC_params = MCMC_params, \n",
    "        structure_names = structure_names,\n",
    "        structure_dimensions = structure_dimensions,        \n",
    "        chain_id = chain_id,\n",
    "        task_id = task_id,\n",
    "        logs = logs, allow_pickle = True,\n",
    "        desc = ''\n",
    "        )\n",
    "    \n",
    "    shutil.copy(filename, submit_dir / 'data')\n",
    "\n",
    "t = time() - t0\n",
    "print(f'{t:.0f} seconds, final saving in {Path.cwd()} / {filename}')\n",
    "print(f'Copying to {submit_dir}/data)')\n",
    "\n",
    "print(f'''\n",
    "Requested MCMC steps: {MCMC_params.N_steps}\n",
    "Time: {timefmt(t)} \n",
    "Estimated task runtime for 1000 steps: {timefmt(t * 1000 / MCMC_params.N_steps)} \n",
    "''')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda3/base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
