{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%run ~/FKMC/notebooks/notebook_preamble.py\n",
    "%matplotlib inline\n",
    "np.seterr(under = 'ignore')\n",
    "from time import time\n",
    "from munch import munchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from operator import mul\n",
    "from functools import reduce\n",
    "from itertools import count\n",
    "from munch import Munch\n",
    "from itertools import zip_longest\n",
    "import logging\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import scipy\n",
    "from FKMC.general import index_histogram_array, sort_IPRs, smooth, shapes, normalise_IPR\n",
    "from FKMC.stats import binned_error_estimate_multidim, product\n",
    "from FKMC.import_funcs import allocate, copy, reshape, execute_script, ProgressReporter, shape_hints, timefmt, update_description\n",
    "\n",
    "#variable classifications\n",
    "N_dependent_size = set(['IPRs', 'eigenvals', 'state','accept_rates', 'classical_accept_rates', 'last_state', 'proposal_rates'])\n",
    "per_step = set([ 'Fc', 'Ff', 'Mf_moments', 'Nc', 'Nf', 'eigenval_bins'])\n",
    "per_run = set(['A', 'N_cumulants','time'])\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def datafile_concat(datafiles, Ns):\n",
    "    #datafiles is a list of lists where the outer is chain_ext and inner is Ns\n",
    "    datafile = [Munch() for _ in Ns]\n",
    "    names = ['IPRs', 'eigenvals', 'Mf_moments', 'eigenval_bins', 'time', 'accept_rates', 'proposal_rates']\n",
    "    \n",
    "    for name in names:\n",
    "        shape = shape_hints(name)\n",
    "        if 'MCstep' in shape:\n",
    "            axis = shape.index('MCstep')\n",
    "        for i, N in enumerate(Ns):\n",
    "            if name == 'time':\n",
    "                datafile[i][name] = np.sum([getattr(log[i], name) for log in datafiles])\n",
    "            elif name == 'eigenval_bins':\n",
    "                log = datafiles[0]\n",
    "                datafile[i][name] = getattr(log[i], name)\n",
    "            else:\n",
    "                datafile[i][name] = np.concatenate([getattr(log[i], name) for log in datafiles], axis = axis)\n",
    "    \n",
    "    return datafile\n",
    "\n",
    "def get_data_funcmap_chain_ext(this_run,\n",
    "            functions = [],\n",
    "            strict_chain_length = True,\n",
    "            ):\n",
    "    \n",
    "    '''\n",
    "    '''\n",
    "    this_run = this_run.expanduser()\n",
    "    logger.warning(f'looking in {this_run}')\n",
    "    data = this_run / 'data'\n",
    "    code = this_run / 'code'\n",
    "    \n",
    "    #get the batch params from the original script\n",
    "    print(list(code.glob('*.py')))\n",
    "    py_script = next(code.glob('*.py'))\n",
    "    context = execute_script(py_script)\n",
    "    batch_params = Munch(context.batch_params)\n",
    "    structure_names = batch_params.structure_names\n",
    "    structure_dims = tuple(d.size for d in batch_params.structure_dimensions)\n",
    "    \n",
    "    logger.debug(f'structure_names = {structure_names}')\n",
    "    logger.debug(f'structure_dims = {structure_dims}')\n",
    "    \n",
    "    #calculate the epected number of jobs\n",
    "    def name2id(n): return tuple(map(int,n.split('_')))\n",
    "    \n",
    "    datafiles = dict()\n",
    "    task_ids = set()\n",
    "    chain_ids = defaultdict(set)\n",
    "    for f in data.glob('*.npz'):\n",
    "        task_id, chain_id = name2id(f.stem)\n",
    "        datafiles[(task_id, chain_id)] = f\n",
    "        task_ids.add(task_id)\n",
    "        chain_ids[task_id].add(chain_id)\n",
    "    \n",
    "    \n",
    "    N_tasks = product(structure_dims)\n",
    "    N_chains = min(max(c) for c in chain_ids.values())\n",
    "    logger.debug(f'Expected number of tasks {N_tasks}')\n",
    "    logger.debug(f'Measured number of tasks {len(task_ids)}')\n",
    "    logger.debug(f'Measured number of chains {N_chains}')\n",
    "    \n",
    "    functions += [extract('time'), mean_over_MCMC('accept_rates'), mean_over_MCMC('proposal_rates')]\n",
    "    \n",
    "    if len(datafiles) == 0: \n",
    "        logger.error(\"NO DATA FILES FOUND\");\n",
    "        return\n",
    "    \n",
    "    #get stuff from an an example datafile\n",
    "    d = Munch(np.load(next(iter(datafiles.values())), allow_pickle = True))\n",
    "    Ns = d['Ns']\n",
    "    parameters = d['parameters'][()]\n",
    "    MCMC_params = d['MCMC_params'][()]\n",
    "    \n",
    "    logger.info(f'Logger keys: {list(d.keys())} \\n')\n",
    "    logger.info(f\"MCMC_params keys: {list(MCMC_params.keys())} \\n\")\n",
    "    \n",
    "    original_N_steps = MCMC_params['N_steps']\n",
    "    thin = MCMC_params['thin']\n",
    "    N_steps = original_N_steps // thin\n",
    "    \n",
    "    logger.debug(list(zip(count(), structure_names, structure_dims)))\n",
    "\n",
    "    possible_observables = [s for s in dir(d.logs[0]) if not s.startswith(\"_\")]\n",
    "    logger.info(f'available observables = {possible_observables}')\n",
    "    \n",
    "    logger.debug(f'Allocating space for the requested observables:')\n",
    "    observables = Munch()\n",
    "    for f in functions: f.allocate(observables, example_datafile = d, N_jobs = N_tasks)\n",
    "    \n",
    "    #copy extra info over, note that structure_names might appear as a key in d, but I just overwrite it for now\n",
    "    observables.update({k : v[()] for k,v in d.items() if k != 'logs'})\n",
    "    observables.structure_names = structure_names\n",
    "    observables.structure_dims = structure_dims\n",
    "    observables.batch_params = batch_params\n",
    "    observables['hints'] = Munch() \n",
    "    \n",
    "    for name, dim in zip(structure_names, batch_params.structure_dimensions):\n",
    "        observables[name] = dim\n",
    "    \n",
    "    for task_id in range(N_tasks):\n",
    "        print(task_id, end = ' ')\n",
    "        datafile_list = np.empty(dtype = object, shape = N_chains)\n",
    "        for chain_id in range(N_chains):\n",
    "            if not (task_id, chain_id) in datafiles:\n",
    "                if strict_chain_length: raise ValueError(f'{(task_id, chain_id)} is expected but missing!')\n",
    "                break\n",
    "            f = datafiles[(task_id, chain_id)]    \n",
    "            datafile_list[chain_id] = np.load(f, allow_pickle = True)['logs']\n",
    "        \n",
    "        datafile = datafile_concat(datafile_list, Ns)\n",
    "        \n",
    "        #convert all those datafiles to one\n",
    "        for f in functions: f.copy(observables, task_id, datafile)\n",
    "    \n",
    "    for f in functions:\n",
    "        f.reshape(structure_dims, observables)\n",
    "    \n",
    "   \n",
    "    logger.info('########################################################################\\n')\n",
    "    logger.info(f'Observables has keys: {observables.keys()}')\n",
    "    \n",
    "    o = observables = Munch(observables)\n",
    "    \n",
    "    infostring = \\\n",
    "    f\"\"\"\n",
    "    Completed jobs:?\n",
    "    MCMC Steps: {original_N_steps} with thinning = {thin} for {N_steps} recorded steps\n",
    "    Burn in: {Munch(MCMC_params).N_burn_in}\n",
    "    Structure_names: {dict(zip(structure_names, structure_dims))}\n",
    "    Ns = {Ns}\n",
    "    Runtimes: \n",
    "        Average: {timefmt(np.nanmean(o.time.sum(axis=0)))}\n",
    "        Min: {timefmt(np.nanmin(o.time.sum(axis=0)))}\n",
    "        Max: {timefmt(np.nanmax(o.time.sum(axis=0)))}\n",
    "        Total: {timefmt(np.nansum(o.time))}\n",
    "    \"\"\"[1:]\n",
    "    logger.info(infostring)\n",
    "    update_description(this_run.stem, infostring)\n",
    "    \n",
    "    return observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FKMC.import_funcs import  mean_over_MCMC, IPRandDOS, extract\n",
    "\n",
    "\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger('local')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "oSingle = get_data_funcmap_chain_ext(Path('~/HPC_data/IPR_DOR_U5_J5_above_below_Tc'),\n",
    "            functions = [\n",
    "                IPRandDOS(E_bins = np.linspace(-20, 20, 10000 + 1)), \n",
    "                mean_over_MCMC('Mf_moments'),\n",
    "                            ],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = oSingle\n",
    "o.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "o = oSmoothed = deepcopy(oSingle)\n",
    "\n",
    "\n",
    "for i, N in zip(count(), o.Ns):\n",
    "    scale = 0.1\n",
    "    for name in ['DOS', 'IPR', 'dDOS', 'dIPR']:\n",
    "        o[name][i] = smooth(o[name][i], scale)\n",
    "\n",
    "\n",
    "f, axes = plt.subplots(2,1, sharex = True, figsize = (14,7))\n",
    "T_select = 3\n",
    "\n",
    "print(o.Ts)\n",
    "for i, N in enumerate(o.Ns):\n",
    "    axes[0].plot(o.E_bins[1:] / o.parameters.U, o.DOS[i, T_select, :], label = f'N = {N}')\n",
    "    axes[1].plot(o.E_bins[1: ] / o.parameters.U, o.IPR[i, T_select, :],)\n",
    "\n",
    "axes[0].set(xlim = (0, 1))\n",
    "f.suptitle(f'T = {o.Ts[T_select]}, J = {o.parameters.J}, U = {o.parameters.U}, M**2 = {o.Mf_moments[-1, :, 2].mean():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.hints.Mf_moments, o.sigma_Mf_moments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FKMC.plotting import spread\n",
    "o = oSingle\n",
    "f, ax = plt.subplots()\n",
    "\n",
    "for i, N in enumerate(o.Ns):\n",
    "    spread(ax, o.Ts, o.Mf_moments[i, :, 2], o.sigma_Mf_moments[i, :, 2], alpha = 0.3, label = f'N = {N}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "oTsweep = get_data_funcmap_chain_ext(Path('~/HPC_data/Tsweep_U5_J5'),\n",
    "            functions = [\n",
    "                #IPRandDOS(E_bins = np.linspace(-20, 20, 10000 + 1)), \n",
    "                mean_over_MCMC('Mf_moments'),\n",
    "                            ],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FKMC.plotting import spread\n",
    "o = oTsweep\n",
    "f, axes = plt.subplots(1,2)\n",
    "\n",
    "d = Munch()\n",
    "d.Ns = o.Ns\n",
    "d.X = o.Ts\n",
    "d.M2 = o.Mf_moments[:, :, 2]\n",
    "d.dM2 = o.sigma_Mf_moments[:, :, 2]\n",
    "d.B =  o.Mf_moments[:, :, 4] / o.Mf_moments[:, :, 2]**2\n",
    "d.dB = None\n",
    "\n",
    "for i, N in enumerate(d.Ns):\n",
    "    axes[0].plot(d.X, d.M2[i])\n",
    "    spread(axes[0], d.X, d.M2[i], d.dM2[i], alpha = 0.3, label = f'N = {N}')\n",
    "    \n",
    "    axes[1].plot(d.X, d.B[i], label = f'N = {N}')\n",
    "    \n",
    "import pickle\n",
    "with open('/home/tch14/HPC_data/pickled_data/binder_data.pickle', 'wb') as file: \n",
    "    pickle.dump(d.toDict(), file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Munch(job_id = 11111).job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
